# Architecture 98.9%
arch: BiT_M_R152x4

# ===== Dataset ===== #
data_url: ../data/imagenet
set: CIFAR10
num_classes: 10
mix_up: 0.1
cutmix: 0.0
auto_augment: None
interpolation: bilinear
re_prob: 0.
re_mode: pixel
re_count: 1
mixup_prob: 1.0
switch_prob: 0.
mixup_mode: batch
image_size: 128
crop_pct: 0.9


# ===== Learning Rate Policy ======== #
optimizer: momentum
base_lr: 0.00075
warmup_lr: 0.0000001
min_lr: 0.0000001
lr_scheduler: multistep_lr
warmup_length: 0

# ===== Network training config ===== #
amp_level: O1
beta: [ 0.9, 0.999 ]
clip_global_norm_value: 5.
is_dynamic_loss_scale: True
epochs: 120
cooldown_epochs: 0
label_smoothing: 0.0
weight_decay: 0.0
momentum: 0.9
batch_size: 16
drop_path_rate: 0.0
pretrained: s3://open-data/pretrained/BiT-M-R152x4.ckpt

# ===== EMA ===== #
with_ema: False
ema_decay: 0.9999

# ===== Hardware setup ===== #
num_parallel_workers: 16
device_target: Ascend